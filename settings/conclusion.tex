\newpage
\section{Zusammenfassung und Fazit}
\label{sec:fazit}
In dieser Arbeit wurde eine effiziente Implementierung eines Softwarepaketes vorgestellt, um Boolesche Funktionen - in Form von ROBDDs - zu manipulieren, was für viele Applikationen bezüglich symbolischer Simulationen oder Model Checking wichtig ist. ROBDDs eignen sich hierzu besser als andere Darstellungen wie KNFs/DNFs, da sie weniger Speicher benötigen und praktische Funktionen wie die Paritätsfunktion effizient darstellen können (siehe Kapitel \ref{sec:dnfknf} auf Seite \pageref{sec:dnfknf}). Darüber hinaus sind Anforderungen wie der Äquivalenztest oder SAT in konstanter Zeit zu bewältigen, die in Kapitel \ref{sec:operationen} auf Seite \pageref{sec:operationen} diskutiert worden sind.\\
Die Implementierung ist im Wesentlichen schneller als eine einfache Implementierung der originalen Algorithmen \cite{b1986}, die von Bryant vorgestellt wurden, was in Kapitel \ref{sec:implementierung} auf Seite \pageref{sec:implementierung} durch algorithmische Analysen gezeigt werden konnte. Damit zusammenhängend ist besonders das Speicherverhalten optimiert worden, da bereits kleinere Optimierungen darüber entscheiden können, ob ein ROBDD überhaupt aufgebaut werden kann. Unittests und statische Code-Analysen haben zudem gezeigt, dass die implementierten Techniken fehlerfrei sind.\\
Dementsprechend führt der Einsatz von SBDDs (siehe Kapitel \ref{sec:sbdds} auf Seite \pageref{sec:sbdds}) dazu, dass Berechnungen schneller stattfinden können bzw. das Speicheraufkommen geringer ist. Durch die Nutzung einer dynamischen CT als Cache (siehe Kapitel \ref{sec:ctable} auf Seite \pageref{sec:ctable}) wird weiterhin der Rechenaufwand/Speicherplatz der Synthese (siehe Kapitel \ref{sec:synthese} auf Seite \pageref{sec:synthese}) verringert, da isomorphe Teilgraphen nicht öfter betrachtet werden müssen, was in Kapitel \ref{sec:experimentelleErgebnisse} auf Seite \pageref{sec:experimentelleErgebnisse} gezeigt werden konnte. Mit dem Einsatz von dynamischen UTs (siehe Kapitel \ref{sec:utable} auf Seite \pageref{sec:utable}) wird hingegen die Kanonizität gesichert. Durch die richtige Wahl der Hashfunktion für die CT bzw. Kollisionsstrategie für die UTs kann die Synthese polynomiell beschränkt, infolge der Tautologieprüfung können wiederum weitere Aufrufe diesbezüglich gespart werden.\\
Weitere Verbesserungen wie komplementäre Kanten (siehe Kapitel \ref{sec:complementEdges} auf Seite \pageref{sec:complementEdges}), Standard-Tripel (siehe Kapitel \ref{sec:standard} auf Seite \pageref{sec:standard}) sowie die Zusammenfassung von Knoten/UTs in eine Datenstruktur (siehe Kapitel \ref{sec:utableBdd} auf Seite \pageref{sec:utableBdd}) führen außerdem dazu, dass das Speicherverhalten sowie die Performanz im Vergleich effizient sind, was durch kleinere BDDs bzw. keine redundanten Berechnungen bedingt wird. Für komplementäre Kanten kann dabei besonders der Umstand von genutzten geraden Adressen in Rechnern ausgenutzt werden, d. h. das LSB von Zeigern wird zur Kodierung dieser Kanten benutzt. Durch derartige und weitere Implementierungstricks kommen demnach auch einige maschinennahe Ansätze zum Einsatz, wodurch CPU-Sekunden nochmals vermindert werden konnten.\\
Insgesamt bleibt jedoch zu erwähnen, dass das BDD-Paket CUDD wesentlich schneller und auch schonender im Umgang mit dem verwendeten Speicher ist (siehe Kapitel \ref{sec:vglCudd} auf Seite \pageref{sec:vglCudd}). Der Grund hierfür liegt wahrscheinlich in der Speicherverwaltung des hier beschriebenen Paketes. Zwar wird der Referenzzähler eines Knotens über eine eingehüllte Klasse automatisch in- und dekrementiert, jedoch dauern -- im Hinblick auf die Kollisionskette in Form eines Vektors -- die Operationen \emph{Einfügen} und \emph{Löschen} merkbar länger, weil sie eine höhere Komplexitätsklasse besitzen. Hier könnte dazu übergegangen werden, dass die Nachfolger direkt im Knoten, anstelle in der UT abgelegt werden (siehe Abbildung \ref{fig:cutableDag} auf Seite \pageref{fig:cutableDag}) und eine verkettete Liste benutzt wird. Darüber hinaus besteht eine insgesamt zu hohe interne Fragmentierung von 10 Bytes pro Knoten. Hier könnte eine Abhilfe sein, dass immer größere Blöcke für Knoten angefordert werden, d.\,h. dass die Speicherverwaltung innerhalb der Blöcke selbst organisiert wird, sodass eine gezielte Partitionierung der Blöcke für die Knoten erfolgt. Zudem könnte in diesem Zusammenhang realisiert werden, dass die UT nicht sofort tote Knoten löscht, sondern bspw. darauf wartet, bis in der CT ein relativer Anteil von $10$ \% tot ist. Hierdurch würde zwar ein größeres Speicheraufkommen bestehen, jedoch bestünde eine Entlastung seitens der UT. Außerdem könnte hierbei eine sog. Wiederbelebung in der CT implementiert werden, sodass tote Knoten reaktiviert und somit eine weitere direkte Berechnung damit gemacht werden kann. Auch eine automatische Erweiterung der UT -- insofern die Kollisionsrate zu hoch wird -- macht in dem Kontext Sinn, wodurch bspw. ein Problem des Rehashings gelöst werden kann \cite[S.78-80]{h2002}. Weiterhin konnte festgestellt werden, dass während der Synthese oftmals ein wiederholtes Interesse von demselben Knoten in der Liste bestand. Wenn demzufolge ein solcher Knoten an den Anfang der Liste gestellt wird, kann eine Suche dementsprechend schneller erfolgen.\\
Abschließend sei hierzu erwähnt, dass das in dieser Arbeit beschriebene Paket natürlich nicht den Funktionsumfang vom langjährig entwickelten CUDD bzw. deren Mechanismen zur Bestimmung einer optimalen Variablenordnung besitzt, kann jedoch dahingehend weiterentwickelt und optimiert werden.